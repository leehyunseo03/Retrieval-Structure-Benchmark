import os
import json
import requests
import re
from datasets import load_dataset
from dotenv import load_dotenv
from tqdm import tqdm

# =========================================================
# [ì„¤ì • ì˜ì—­]
# =========================================================
load_dotenv()
BASE_DIR = os.environ.get('FinanceBench_DIR')
FB_DATA_DIR = os.path.join(BASE_DIR, "financebench")
PDF_DIR = os.path.join(BASE_DIR, "financebench_pdfs")
JSON_SAVE_PATH = os.path.join(FB_DATA_DIR, "financebench_data.json")

# ë‹¤ìš´ë¡œë“œí•  PDF ê°œìˆ˜ ì œí•œ (Noneì´ë©´ ì „ì²´ - ì•½ 100ê°œ ë‚´ì™¸ì§€ë§Œ íŒŒì¼ì´ í¼)
LIMIT_PDF_DOWNLOAD = 30 

# =========================================================
# [ê¸°ëŠ¥ êµ¬í˜„]
# =========================================================

def setup_directories():
    if not os.path.exists(FB_DATA_DIR):
        os.makedirs(FB_DATA_DIR)
    if not os.path.exists(PDF_DIR):
        os.makedirs(PDF_DIR)
    print(f"ğŸ“‚ ë””ë ‰í† ë¦¬ í™•ì¸:\n - JSON: {FB_DATA_DIR}\n - PDF: {PDF_DIR}")

def sanitize_filename(name):
    """íŒŒì¼ëª…ìœ¼ë¡œ ì“¸ ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±° ë° ê³µë°± ì²˜ë¦¬"""
    name = re.sub(r'[\\/*?:"<>|]', "", name)
    return name.replace(" ", "_")

def download_and_process_data():
    print("â¬‡ï¸  Hugging Faceì—ì„œ FinanceBench ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    try:
        # FinanceBenchëŠ” ë³´í†µ 'train' ìŠ¤í”Œë¦¿ í•˜ë‚˜ë§Œ ì¡´ì¬í•¨
        ds = load_dataset("PatronusAI/financebench", split="train")
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

    formatted_data = {}
    unique_docs = {} # PDF ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ ì¤‘ë³µ ì œê±°ìš© ë”•ì…”ë„ˆë¦¬ {doc_name: doc_link}

    print("ğŸ”„ ë°ì´í„° ë³€í™˜ ë° PDF ë§í¬ ì¶”ì¶œ ì¤‘...")
    for entry in ds:
        # FinanceBenchì˜ ê³ ìœ  ì‹ë³„ìëŠ” financebench_id
        qid = entry.get('financebench_id')
        doc_name = entry.get('doc_name')
        doc_link = entry.get('doc_link')
        
        # íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜
        safe_doc_name = sanitize_filename(doc_name)
        
        # ë‹¤ìš´ë¡œë“œ ëª©ë¡ì— ì¶”ê°€
        if safe_doc_name not in unique_docs and doc_link:
            unique_docs[safe_doc_name] = doc_link

        # í‰ê°€ìš© ë°ì´í„° êµ¬ì¡° ìƒì„±
        # êµ¬ì¡°: { "DOC_NAME": { "questions": [...] } } í˜•íƒœë¡œ ì €ì¥ (ë¬¸ì„œ ì¤‘ì‹¬)
        if safe_doc_name not in formatted_data:
            formatted_data[safe_doc_name] = {
                "original_doc_name": doc_name,
                "doc_link": doc_link,
                "qas": []
            }
        
        formatted_data[safe_doc_name]["qas"].append({
            "qid": qid,
            "question": entry.get('question'),
            "answer": entry.get('answer'), # ì •ë‹µ í…ìŠ¤íŠ¸
            "evidence_text": entry.get('evidence_text'), # ê·¼ê±° ë¬¸ì¥
            "page_number": entry.get('page_number')
        })

    # JSON ì €ì¥
    with open(JSON_SAVE_PATH, 'w', encoding='utf-8') as f:
        json.dump(formatted_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… JSON ë°ì´í„° ì €ì¥ ì™„ë£Œ: {JSON_SAVE_PATH}")
    return unique_docs

def download_pdfs(doc_map):
    print(f"\nâ¬‡ï¸  PDF ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ì´ {len(doc_map)}ê°œ ë¬¸ì„œ ì¤‘ {LIMIT_PDF_DOWNLOAD if LIMIT_PDF_DOWNLOAD else 'ì „ì²´'} ëŒ€ìƒ)")
    
    target_docs = list(doc_map.items())
    if LIMIT_PDF_DOWNLOAD:
        target_docs = target_docs[:LIMIT_PDF_DOWNLOAD]
    
    success = 0
    fail = 0
    skipped = 0

    for doc_name, link in tqdm(target_docs, desc="Downloading PDFs"):
        save_path = os.path.join(PDF_DIR, f"{doc_name}.pdf")
        
        if os.path.exists(save_path):
            skipped += 1
            continue
            
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            response = requests.get(link, headers=headers, timeout=60, stream=True)
            
            if response.status_code == 200:
                with open(save_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                success += 1
            else:
                # print(f"Failed {doc_name}: Status {response.status_code}")
                fail += 1
        except Exception as e:
            # print(f"Error {doc_name}: {e}")
            fail += 1
            
    print("\n" + "="*40)
    print(f"ğŸ‰ ë‹¤ìš´ë¡œë“œ ê²°ê³¼")
    print(f" - ì„±ê³µ: {success}")
    print(f" - ì‹¤íŒ¨: {fail}")
    print(f" - ìŠ¤í‚µ(ì´ë¯¸ ìˆìŒ): {skipped}")
    print(f" - ì €ì¥ ê²½ë¡œ: {PDF_DIR}")
    print("="*40)

if __name__ == "__main__":
    setup_directories()
    
    # 1. ë°ì´í„° ì²˜ë¦¬ ë° ë§í¬ ì¶”ì¶œ
    docs_to_download = download_and_process_data()
    
    # 2. PDF ë‹¤ìš´ë¡œë“œ
    if docs_to_download:
        download_pdfs(docs_to_download)