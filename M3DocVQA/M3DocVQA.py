import os
import json
import ujson
import fitz  # PyMuPDF
import time
import random
import shutil
import datetime
from dotenv import load_dotenv
from typing import List, Tuple, Dict, Any, Set
from dataclasses import dataclass
from tqdm import tqdm
from PIL import Image

# LlamaIndex ê´€ë ¨ ì„í¬íŠ¸
from llama_index.core import (
    Document,
    VectorStoreIndex,
    Settings,
    StorageContext,
    SimpleDirectoryReader,
    PropertyGraphIndex
)
from llama_index.core.indices.property_graph import SimpleLLMPathExtractor
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from google import genai

# =========================================================
# [ì„¤ì • ì˜ì—­] API KEY ë° ê²½ë¡œ
# =========================================================

# 1. API í‚¤ ì„¤ì •
load_dotenv()
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')

# 2. ë°ì´í„° ê²½ë¡œ ì„¤ì •
# M3DocVQA ë°ì´í„°ì…‹ì´ ìˆëŠ” í´ë” ê²½ë¡œ
BASE_DIR =  os.environ.get('M3DocVQA_DIR')
PDF_DIR = os.path.join(BASE_DIR, "pdfs_dev") # PDF íŒŒì¼ë“¤ì´ ë“¤ì–´ìˆëŠ” í´ë”
DEV_QA_PATH = os.path.join(BASE_DIR, "multimodalqa", "MMQA_dev.jsonl") # ì§ˆë¬¸ì§€ íŒŒì¼

# 3. ëª¨ë¸ ì„¤ì •
Settings.llm = OpenAI(model="gpt-4o-mini", temperature=0)
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")

client = genai.Client(api_key=GOOGLE_API_KEY)
vision_model_id = 'gemini-2.0-flash'

# 4. í‰ê°€ ì„¤ì •
TOP_K_LIST = [1, 3, 5, 10]
LIMIT_PDFS = 30  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì²˜ë¦¬í•  PDF ê°œìˆ˜ ì œí•œ (ì „ì²´ëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼). 0ì´ë©´ ì „ì²´ ì‹¤í–‰.

# =========================================================
# [Part 1] ë°ì´í„° ë¡œë” ë° ì „ì²˜ë¦¬ (M3DocVQA í˜•ì‹)
# =========================================================

@dataclass
class QAExample:
    qid: str
    question: str
    answers: List[str]
    positive_doc_ids: Set[str]

def load_mmqa_data(jsonl_path: str) -> List[QAExample]:
    qa_list = []
    if not os.path.exists(jsonl_path):
        print(f"[Error] QA íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jsonl_path}")
        return []

    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line: continue
            ex = ujson.loads(line)

            qid = ex.get("qid") or str(ex.get("id"))
            question = ex["question"]
            
            # ì •ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            answers = [a["answer"] if isinstance(a, dict) else a for a in ex.get("answers", [])]
            
            # [í•µì‹¬ ìˆ˜ì •] supporting_contextì—ì„œ doc_id ì¶”ì¶œ
            positive_doc_ids = set()
            
            # 1. supporting_context í™•ì¸
            if "supporting_context" in ex:
                for ctx in ex["supporting_context"]:
                    doc_id = ctx.get("doc_id")
                    if doc_id:
                        positive_doc_ids.add(str(doc_id))
            
            # 2. metadata ë‚´ image_doc_ids ë“± í™•ì¸ (ë³´ì¡°)
            if "metadata" in ex:
                meta = ex["metadata"]
                if "image_doc_ids" in meta:
                    for img_id in meta["image_doc_ids"]:
                        # ì§ˆë¬¸ê³¼ ì—°ê´€ëœ ì´ë¯¸ì§€ê°€ ëª…í™•í•˜ë©´ ì¶”ê°€í•  ìˆ˜ë„ ìˆìœ¼ë‚˜, 
                        # ë³´í†µ supporting_contextê°€ ì •ë‹µ ê·¼ê±°ì„. ì—¬ê¸°ì„  supporting_contextê°€ ë¹„ì—ˆì„ ë•Œë§Œ ê³ ë ¤
                        if not positive_doc_ids: 
                            pass # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ supporting_contextë§Œ ì‹ ë¢°í•¨

            if positive_doc_ids:
                qa_list.append(QAExample(qid, question, answers, positive_doc_ids))
            
    return qa_list

# =========================================================
# [Part 2] ì‚¬ìš©ì ì»¤ìŠ¤í…€ ì¸ë±ì‹± (MongoDB ì œê±°, Gemini ìº¡ì…˜ í¬í•¨)
# =========================================================

def generate_image_caption(image_path: str) -> str:
    """Google Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        img = Image.open(image_path)
        if img.width < 100 or img.height < 100:
            return "ì‹ë³„ ë¶ˆê°€ëŠ¥í•œ ì‘ì€ ì´ë¯¸ì§€ ë˜ëŠ” ì•„ì´ì½˜"

        prompt = (
            "Describe this image in detail for a search engine. "
            "If it's a chart, include the numbers. If it's text, summarize it."
        )
        time.sleep(1.5) # Rate Limit ê³ ë ¤
        response = client.models.generate_content(model=vision_model_id, contents=[prompt, img])
        return response.text if response.text else "ì„¤ëª… ìƒì„± ì‹¤íŒ¨"
    except Exception as e:
        # print(f"   [Caption Error] {str(e)[:50]}...")
        return "ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

class SmartPDFLoader:
    def __init__(self, pdf_dir: str, output_img_dir: str = "temp_images"):
        self.pdf_dir = pdf_dir
        self.output_img_dir = output_img_dir
        if os.path.exists(self.output_img_dir):
            shutil.rmtree(self.output_img_dir)
        os.makedirs(self.output_img_dir, exist_ok=True)

    def load_specific_documents(self, target_doc_ids: Set[str]) -> List[Document]:
        all_docs = []
        
        # íŒŒì¼ëª… ë§¤ì¹­
        available_files = {f.split('.')[0]: f for f in os.listdir(self.pdf_dir) if f.lower().endswith(".pdf")}
        
        found_files = []
        for tid in target_doc_ids:
            if tid in available_files:
                found_files.append(available_files[tid])
        
        if not found_files:
            return []

        for filename in tqdm(found_files, desc="ğŸ“‚ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘", unit="file"):
            filepath = os.path.join(self.pdf_dir, filename)
            doc_id = filename.split('.')[0] # í™•ì¥ì ëº€ íŒŒì¼ëª…ì„ doc_idë¡œ ì‚¬ìš©
            
            # 1. í…ìŠ¤íŠ¸
            try:
                text_docs = SimpleDirectoryReader(input_files=[filepath]).load_data()
                for d in text_docs:
                    d.metadata["doc_id"] = doc_id
                all_docs.extend(text_docs)
            except:
                pass
            """
            # 2. ì´ë¯¸ì§€
            try:
                fitz_doc = fitz.open(filepath)
                for page_idx, page in enumerate(fitz_doc):
                    image_list = page.get_images(full=True)
                    if not image_list: continue

                    for img_idx, img in enumerate(image_list):
                        try:
                            xref = img[0]
                            base_image = fitz_doc.extract_image(xref)
                            saved_path = os.path.join(self.output_img_dir, f"{doc_id}_p{page_idx}_{img_idx}.{base_image['ext']}")
                            with open(saved_path, "wb") as f:
                                f.write(base_image["image"])
                            
                            caption = generate_image_caption(saved_path)
                            img_doc = Document(
                                text=f"[ì´ë¯¸ì§€ ì„¤ëª…]\níŒŒì¼: {filename} p.{page_idx+1}\në‚´ìš©: {caption}",
                                metadata={"doc_id": doc_id, "page_label": str(page_idx + 1), "type": "image"}
                            )
                            all_docs.append(img_doc)
                        except:
                            continue
                fitz_doc.close()
            except:
                pass
            """
        return all_docs
    
# =========================================================
# [Part 3] ì‹¤í–‰ ë° í‰ê°€ (MMQA ë¡œì§ ì ìš©)
# =========================================================

def evaluate_system():
    print("\n" + "="*40)
    print("ğŸš€ MMQA í‰ê°€ ì‹œìŠ¤í…œ ì‹œì‘ (Quiet Mode)")
    print("="*40)

    # 1. QA ë°ì´í„° ë¡œë“œ
    full_qa_list = load_mmqa_data(DEV_QA_PATH)
    if not full_qa_list: return

    # 2. í•„ìš”í•œ ë¬¸ì„œ ID ì¶”ì¶œ
    needed_doc_ids = set()
    for qa in full_qa_list:
        needed_doc_ids.update(qa.positive_doc_ids)
            
    # PDF í´ë” ìŠ¤ìº”
    available_pdfs = set(f.split('.')[0] for f in os.listdir(PDF_DIR) if f.endswith(".pdf"))
    
    # êµì§‘í•© í™•ì¸
    valid_doc_ids = list(needed_doc_ids.intersection(available_pdfs))
    
    if not valid_doc_ids:
        print("âŒ ì§ˆë¬¸ì§€ì˜ doc_idì™€ ì¼ì¹˜í•˜ëŠ” PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì˜ˆì‹œ QA doc_id: {list(needed_doc_ids)[:3]}")
        print(f"ì˜ˆì‹œ PDF íŒŒì¼ëª…: {list(available_pdfs)[:3]}")
        return

    random.shuffle(valid_doc_ids)
    target_doc_ids = set(valid_doc_ids[:LIMIT_PDFS])
    
    print(f"ğŸ“‹ ì „ì²´ QA: {len(full_qa_list)}ê°œ")
    print(f"ğŸ¯ ë§¤ì¹­ëœ ë¬¸ì„œ ì¤‘ {len(target_doc_ids)}ê°œë§Œ ë¡œë“œí•˜ì—¬ í‰ê°€ ì§„í–‰ (LIMIT)")

    # 3. ë¬¸ì„œ ë¡œë“œ
    loader = SmartPDFLoader(PDF_DIR)
    docs = loader.load_specific_documents(target_doc_ids)
    
    # 4. ì¸ë±ìŠ¤ ìƒì„±
    print(f"ğŸ—ï¸  Knowledge Graph ìƒì„± ì¤‘... ({len(docs)})")
    index = PropertyGraphIndex.from_documents(
        docs,
        embed_model=Settings.embed_model,
        llm=Settings.llm,
        kg_extractors=[SimpleLLMPathExtractor(llm=Settings.llm, max_paths_per_chunk=5)],
        show_progress=False 
    )
    
    retriever = index.as_retriever(include_text=True, similarity_top_k=max(TOP_K_LIST))

    # 5. í‰ê°€ ëŒ€ìƒ í•„í„°ë§ (ë¡œë“œí•œ ë¬¸ì„œì— ëŒ€í•œ ì§ˆë¬¸ë§Œ)
    filtered_qa_list = []
    for qa in full_qa_list:
        # ì§ˆë¬¸ì˜ ì •ë‹µ ë¬¸ì„œ(positive_doc_ids) ì¤‘ í•˜ë‚˜ë¼ë„ ë¡œë“œëœ ë¬¸ì„œ(target_doc_ids)ì— ìˆìœ¼ë©´ í‰ê°€
        if not qa.positive_doc_ids.isdisjoint(target_doc_ids):
            filtered_qa_list.append(qa)
            
    print(f"ğŸ” ê´€ë ¨ ì§ˆë¬¸ {len(filtered_qa_list)}ê°œì— ëŒ€í•´ í‰ê°€ ì§„í–‰")

    # 6. í‰ê°€ ë£¨í”„
    metrics = {f"recall@{k}": 0.0 for k in TOP_K_LIST}
    metrics.update({f"mrr@{k}": 0.0 for k in TOP_K_LIST})
    
    for i, ex in enumerate(tqdm(filtered_qa_list, desc="ğŸ“ í‰ê°€ ì§„í–‰ ì¤‘", unit="Q")):
        try:
            nodes = retriever.retrieve(ex.question)
        except:
            nodes = []

        retrieved_docs = []
        retrieved_details = []
        retrieved_doc_ids = []

        # ê²€ìƒ‰ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        retrieved_doc_ids = []
        for node in nodes:
            r_doc_id = node.metadata.get("doc_id", "")
            retrieved_doc_ids.append(r_doc_id)

            content_preview = node.text[:100].replace('\n', ' ') + "..."
            retrieved_details.append(f"[{r_doc_id}] {content_preview}")

        # ì •ë‹µì…‹ (ë¬¸ì„œ ID)
        gt_set = ex.positive_doc_ids

        # --- [ìƒì„¸ ê²°ê³¼ ì¶œë ¥ ë¶€ë¶„] ---
        tqdm.write("\n" + "-"*60)
        tqdm.write(f"ğŸ“Œ [Question #{i+1}] {ex.question}")
        tqdm.write(f"âœ… ì •ë‹µ(GT Doc IDs): {list(gt_set)}")
        tqdm.write(f"ğŸ’¬ ì •ë‹µ í…ìŠ¤íŠ¸(ì°¸ê³ ìš©): {ex.answers}")
        tqdm.write(f"ğŸ” ì˜ˆì¸¡(Retrieved Top-{max(TOP_K_LIST)}):")
        for rank, detail in enumerate(retrieved_details, 1):
            tqdm.write(f"   {rank}. {detail}")
        
        # ê²°ê³¼ íŒì • (Top-5 ê¸°ì¤€ Hit ì—¬ë¶€ ì¶œë ¥)
        hit_check = any(d in gt_set for d in retrieved_doc_ids[:5])
        tqdm.write(f"ğŸ¯ ê²°ê³¼: {'â­• Hit' if hit_check else 'âŒ Miss'}")
        tqdm.write("-" * 60)
        # ---------------------------

        for k in TOP_K_LIST:
            current_top_k = retrieved_doc_ids[:k]
            
            # Recall Check: Top-K ì•ˆì— ì •ë‹µ ë¬¸ì„œ IDê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€
            is_hit = any(did in gt_set for did in current_top_k)
            if is_hit: 
                metrics[f"recall@{k}"] += 1.0
            
            # MRR Check
            for rank, did in enumerate(current_top_k, start=1):
                if did in gt_set:
                    metrics[f"mrr@{k}"] += 1.0 / rank
                    break

    # 7. ê²°ê³¼ ì¶œë ¥
    count = len(filtered_qa_list)
    print("\n" + "="*30)
    print(f"ğŸ“Š ìµœì¢… ê²°ê³¼ (Samples: {count})")
    print("="*30)
    
    if count > 0:
        for k in TOP_K_LIST:
            recall = metrics[f'recall@{k}']/count
            mrr = metrics[f'mrr@{k}']/count
            print(f"K={k:<2} | Recall: {recall:.4f} | MRR: {mrr:.4f}")
    
    if os.path.exists("temp_images"):
        shutil.rmtree("temp_images")

if __name__ == "__main__":
    evaluate_system() 